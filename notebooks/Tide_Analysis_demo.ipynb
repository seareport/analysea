{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a040d444",
   "metadata": {},
   "source": [
    "# Tide Analysis demonstration for Acapulco tide gauge (IOC)\n",
    "\n",
    "to make this notebook running, you need: the following packages: \n",
    "\n",
    "xarray, pandas, geopandas, ruptures, searvey, utide, cartopy, shapely, matplotlib\n",
    "\n",
    "See [README.md](https://github.com/tomsail/analysea) for more information\n",
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197ecd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysea.filters import *\n",
    "from analysea.utils import detect_gaps, completeness, correct_unit\n",
    "from analysea.plot import plot_gaps, plot_multiyear_tide_analysis\n",
    "from analysea.steps import step_function_ruptures\n",
    "from analysea.spikes import despike_prominence\n",
    "from analysea.spikes import EWMA \n",
    "from analysea.spikes import remove_spikes\n",
    "from analysea.spikes import buffer_nans\n",
    "from analysea.tide import yearly_tide_analysis, demean_amps_phases\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a0c8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from searvey import ioc\n",
    "ioc_stations = ioc.get_ioc_stations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc045ca",
   "metadata": {},
   "source": [
    "## load test case : Acapulco (Mex)\n",
    "\n",
    "but you can also try with the other stations in the data folder !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43767b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ioc_station = \"acap2\" \n",
    "df0 = pd.read_parquet('../tests/data/'+_ioc_station+'.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2fa529",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"slevel\"] = remove_numerical(df0.slevel)\n",
    "df['correct'], units_flag = correct_unit(df.slevel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c8f7ba",
   "metadata": {},
   "source": [
    "# flag the signal\n",
    "we will start \"flagging\" the signal to clean it from bad values\n",
    "\n",
    "## first units\n",
    "some signals comport different units from the beginning to the end \n",
    "\n",
    "example: for ```acap2``` : the beggining in mm and finishing years in m (the norm being in meters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460a28da",
   "metadata": {},
   "source": [
    "## then, detect steps\n",
    "\n",
    "we will use here the Linearly penalized segmentation (Pelt) from the [ruptures](https://centre-borelli.github.io/ruptures-docs/user-guide/detection/pelt/) package\n",
    "the rest of the processing will be easier once steps will be removed from the signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c83d254",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['step'], stepsx, steps = step_function_ruptures(df.correct)\n",
    "fig, ax = plt.subplots()\n",
    "df.correct.plot(ax=ax, color='k')\n",
    "df.step.plot(ax=ax,color= 'r',linestyle='--')\n",
    "if (len(stepsx) > 2) & (np.max(steps)>1):\n",
    "    for i, isteps in enumerate(stepsx[:-1]):\n",
    "        ax.axvline(x=df.index[isteps], color='k', linestyle='--')\n",
    "    ipeaks, peaks, df['correct'] = despike_prominence(df.correct - df.step, 1) # despike once already"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f59c21e",
   "metadata": {},
   "source": [
    "## spikes\n",
    "First we will remove the spikes from the signal, defining : \n",
    "\n",
    "*NB: it is important to remove the mean after despike https://doi.org/10.3390/rs12233970*\n",
    "\n",
    "### Method 1: \n",
    "Doing the difference between the 'spikey' signal and Forward/Backward exponential weighted moving average (EWMA). \n",
    "The difference higher than 3 * standard deviation is removed \n",
    "\n",
    "from [here](https://stackoverflow.com/questions/37556487/remove-spikes-from-signal-in-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf7ffa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ewma'] = EWMA(df.slevel, 10)\n",
    "df['despiked'] = remove_spikes(df.slevel, df.ewma, 3*df.slevel.std())\n",
    "df['clean'] = buffer_nans(df.despiked, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19219c53",
   "metadata": {},
   "source": [
    "### Method 2 (default): \n",
    "Eliminating the absolute values of the signal surpassing a threshold equivalento to 3 time the standard deviation. \n",
    "We use Scipy's find_peak() function with a prominence set to ```3*df.std()```\n",
    "\n",
    "Links & refs: \n",
    " * [Scipy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.find_peaks.html)\n",
    " * [StackOverFlow](https://stackoverflow.com/questions/1713335/peak-finding-algorithm-for-python-scipy)\n",
    " * [Prominence - Wikipedia](https://en.wikipedia.org/wiki/Topographic_prominence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e33b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "prom = np.max([3*df.correct.std(),1])\n",
    "fig, ax = plt.subplots()\n",
    "df.correct.plot(ax=ax)\n",
    "ipeaks, peaks, df['anomaly'] = despike_prominence(df.correct, prom)\n",
    "ax.plot(df.index[ipeaks], peaks, 'ob')\n",
    "df.anomaly.plot(ax=ax, color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ea6141",
   "metadata": {},
   "source": [
    "## Signal to Noise and filtering \n",
    "### filter if the signal is noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358fae34",
   "metadata": {},
   "outputs": [],
   "source": [
    "if signaltonoise(df.slevel)<0: \n",
    "    df['filtered'] = filter_fft(df.anomaly)\n",
    "    \n",
    "print(signaltonoise(df.anomaly))\n",
    "print(signaltonoise(df.filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37dbaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "df.anomaly.iloc[2300000:2310000].plot(ax=ax)\n",
    "df.filtered.iloc[2300000:2310000].plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1389a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.anomaly = df.filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73c57a0",
   "metadata": {},
   "source": [
    "## Check continuity of the time series and detect gaps\n",
    "first some functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7ddc3b",
   "metadata": {},
   "source": [
    "\n",
    "we need to detect gaps either : \n",
    " * interpolate between small gaps (less than a hour)\n",
    " * drop data between big gaps (less than a consecutive year)\n",
    "### First, detect all gaps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98865349",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaps, small_gaps, big_gaps = detect_gaps(df)\n",
    "print(f'{len(small_gaps)} small gaps with average gap duration: {small_gaps.mean()}')\n",
    "print(f'{len(big_gaps)} bigs gaps with average gap duration: {big_gaps.mean()}')\n",
    "print(f'with the biggest gap being : {big_gaps.max()}')\n",
    "filenameOutGaps = '../tests/data/graphs/' +  _ioc_station + '_gaps.png'\n",
    "plot_gaps(df.anomaly,big_gaps,filenameOutGaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4a44e2",
   "metadata": {},
   "source": [
    "## check if the time series is worth the tide analysis\n",
    "if the total time is less than year, we should disregard the time series \n",
    "\n",
    "let's define 60 minutes for the minimum interval of no data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacbe24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "completeness(df.anomaly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06768eab",
   "metadata": {},
   "source": [
    "# Detide the signal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22af05e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = {'conf_int': 'linear',\n",
    "        'constit' : 'auto',\n",
    "        'method' : 'ols', # ols is faster and good for missing data (Ponchaut et al., 2001)\n",
    "        'order_constit' : 'frequency',\n",
    "        'Rayleigh_min' : 0.97,\n",
    "        'lat': None,\n",
    "        'verbose' : True,\n",
    "} # careful if there is only one Nan parameter, the analysis crashes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2962ea2e",
   "metadata": {},
   "source": [
    "### (de)tide analysis\n",
    "we analyse the signal by yearly chunks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e23af8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.anomaly.reset_index().drop_duplicates(subset=\"time\", keep=\"last\").set_index(\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2601a125",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa72ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts['lat'] = ioc_stations.iloc[np.where(ioc_stations.ioc_code==_ioc_station)[0][0]].lat\n",
    "df['tide'], df['surge'], coefs, years = yearly_tide_analysis(df1.anomaly, 365, opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fc023d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constituent to keep\n",
    "keep_const = ['M2', 'S2', 'N2', 'O1', 'K2', 'K1',  'NU2', 'Q1', 'L2', 'P1',\n",
    "            '2N2', 'M4', 'MS4', 'MM',  'MU2', 'SSA', 'LDA2',  'MF', 'MSM', 'MN4']\n",
    "ASTRO_WRITE = [\"M2\",\"S2\",\"N2\",\"O1\",\"K2\",\"K1\",\"NU2\",\"Q1\",\"L2\",\"P1\",\"2N2\",\"M4\",\"MS4\",\n",
    "               \"MM\",\"MU2\",\"SSA\",\"LDA2\",\"MF\",\"MSM\",\"MN\"]\n",
    "lat =  ioc_stations.iloc[np.where(ioc_stations.ioc_code==_ioc_station)[0][0]].lat\n",
    "lon =  ioc_stations.iloc[np.where(ioc_stations.ioc_code==_ioc_station)[0][0]].lon\n",
    "title =  ioc_stations.iloc[np.where(ioc_stations.ioc_code==_ioc_station)[0][0]].location\n",
    "_ioc_code = _ioc_station\n",
    "filenameOut = '../tests/data/graphs/' + _ioc_code + '.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0621a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiyear_tide_analysis(keep_const, coefs, years, lat, lon, df, title, filenameOut )\n",
    "plot_multiyear_tide_analysis(keep_const, coefs, years, lat, lon, df, title, filenameOut, zoom=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b944807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "const, means_amps,mean_phases = demean_amps_phases(coefs, coefs[0]['name'])\n",
    "data={\n",
    "    'lat':lat,\n",
    "    'lon':lon,\n",
    "    'const_name': const.tolist(),\n",
    "    'means_amps': (means_amps).tolist(),\n",
    "    'mean_phases': mean_phases.tolist(),\n",
    "    'missing': 100 - completeness(df.anomaly),\n",
    "    'perc_analysed': len(df.surge) / len(df.slevel),\n",
    "    'biggest_gap' : str(big_gaps.max()),\n",
    "    'total_gap' : len(gaps),\n",
    "    'steps_flag': len(stepsx),\n",
    "    'unit_flag': units_flag,\n",
    "    'snr': signaltonoise(df.slevel).tolist(),\n",
    "    'first_obs' : pd.Timestamp(df.index.min()).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'last_obs' :  pd.Timestamp(df.index.max()).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'code': _ioc_code,\n",
    "}\n",
    "resout = pd.DataFrame(data)\n",
    "with open(f'../tests/data/processed/{_ioc_code}.json', 'w') as f:\n",
    "    json.dump(data, f)\n",
    "# resout.to_csv(f'../tests/data/processed/{_ioc_code}.csv', index=False)\n",
    "# out = pd.DataFrame(data=df.surge, index=df.index)\n",
    "# out.to_parquet(f'../tests/data/processed/{_ioc_code}_surge.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff515a2",
   "metadata": {},
   "source": [
    "## do the mean on all utide returned coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c34b6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "const, mean_amps,mean_phases = demean_amps_phases(coefs, coefs[0]['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cac6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_format(d):\n",
    "    for key, value in d.items():\n",
    "        if isinstance(value, dict):\n",
    "            json_format(value)  # Recurse into nested dictionaries\n",
    "        elif isinstance(value, np.ndarray):\n",
    "            d[key] = value.tolist()  # Convert NumPy array to list\n",
    "        elif isinstance(value, pd.Timestamp):\n",
    "            d[key] = value.strftime('%Y-%m-%d %H:%M:%S')  # Convert pandas Timestamp to string\n",
    "        elif isinstance(value, pd.Timedelta):\n",
    "            d[key] = str(value)  # Convert pandas Timedelta to string\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0ab3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "js_out = json_format(coefs[-1])\n",
    "js_out['weights'] = 0 # weights list is too long and unused in the reconstruction\n",
    "js_out['A'] = mean_amps.tolist()\n",
    "js_out['g'] = mean_phases.tolist()\n",
    "# js_out = js_out.pop('weights')\n",
    "for key in data.keys():\n",
    "    js_out[key] = data[key]\n",
    "with open(f\"./data/processed/acap2_test.json\", \"w\") as fp:\n",
    "    json.dump(js_out, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f86452",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_out = coefs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4582ed8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_out['A'] = mean_amps\n",
    "coef_out['g'] = mean_phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb22c61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
